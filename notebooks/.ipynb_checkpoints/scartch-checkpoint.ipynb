{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.layers import GlobalAveragePooling2D,Flatten\n",
    "from keras.models import Model\n",
    "ResNet34, preprocess_input = Classifiers.get('resnet34')\n",
    "\n",
    "n_classes = 7\n",
    "\n",
    "# build model\n",
    "base_model = ResNet34(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
    "model =Sequential()\n",
    "model.add(base_model)\n",
    "headModel = model.output\n",
    "#headModel = AveragePooling2D(pool_size=(19, 19))\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(7, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=model.input, outputs=headModel)\n",
    "#x = keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "#output = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "#model = keras.models.Model(inputs=[model.input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(GlobalAveragePooling2D())\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(512,activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# with a Sequential model\n",
    "get_6rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[-3].output])\n",
    "layer_output = get_6rd_layer_output([img_data])[0]\n",
    "\n",
    "#print shape\n",
    "print(layer_output.shape)\n",
    "\n",
    "#print the numpy array output flatten layer\n",
    "print(layer_output.shape)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stock(img_data):\n",
    "    plt.figure(1, figsize=(10, 10))\n",
    "    stock = np.squeeze(img_data, axis=0)\n",
    "    print(stock.shape)\n",
    "    plt.imshow(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_stock(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img_path = '../Dataset/test/Blackrot/Blackrot 1242.JPG'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "vgg_feature = model.predict(img_data)\n",
    "#print the shape of the output (so from your architecture is clear will be (1, 128))\n",
    "#print shape\n",
    "print(vgg_feature.shape)\n",
    "vgg_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "logdir = os.path.join(\"resnet34logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, batch_size=32,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                        embeddings_data=train_generator)\n",
    "tb = TensorBoard(logdir, histogram_freq=1, batch_size=32, write_graph=True, write_grads=False, write_images=True, embeddings_freq=1, embeddings_layer_names=['features'], embeddings_metadata='metadata.tsv', embeddings_data=train_batches, update_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(batch_size=32,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=train_datagen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_feature_list = []\n",
    "\n",
    "for idx, dirname in enumerate(subdir):\n",
    "    # get the directory names, i.e., 'dogs' or 'cats'\n",
    "    # ...\n",
    "    \n",
    "    for i, fname in enumerate(filenames):\n",
    "        # process the files under the directory 'dogs' or 'cats'\n",
    "        # ...\n",
    "        \n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = vgg16_preprocess(img_data)\n",
    "\n",
    "        vgg16_feature = model_vgg16.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "        \n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(vgg16_feature_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model.summary()\n",
    "\n",
    "img_path = 'train/dogs/1.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)\n",
    "\n",
    "print vgg16_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_path = '../Dataset/test/Blackrot/Blackrot 1242.JPG'\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "vgg_feature = vgg16_model.predict(img_data)\n",
    "vgg_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# with a Sequential model\n",
    "get_6rd_layer_output = K.function([vgg16_model.layers[0].input],\n",
    "                                  [vgg16_model.layers[-3].output])\n",
    "#layer_output = get_6rd_layer_output([img_data])[0]\n",
    "\n",
    "#print shape\n",
    "#|print(layer_output.shape)\n",
    "\n",
    "#print the numpy array output flatten layer\n",
    "#print(layer_output.shape)\n",
    "#layer_output\n",
    "#image_features[0,:] =get_6rd_layer_output([im])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_file_name):\n",
    "    ''' Runs the given image_file to VGG 16 model and returns the \n",
    "    weights (filters) as a 1, 4096 dimension vector '''\n",
    "    #image_features = np.zeros((1, 4096))\n",
    "    image_features = np.zeros((1, 512))\n",
    "    # Magic_Number = 4096  > Comes from last layer of VGG Model\n",
    "\n",
    "    # Since VGG was trained as a image of 224x224, every new image\n",
    "    # is required to go through the same transformation\n",
    "    im = cv2.resize(cv2.imread(image_file_name), (256, 256))\n",
    "\n",
    "\n",
    "    # The mean pixel values are taken from the VGG authors, which are the values computed from the training dataset.\n",
    "    #mean_pixel = [103.939, 116.779, 123.68]\n",
    "\n",
    "    im = im.astype(np.float32, copy=False)/255 # shape of im = (224,224,3)\n",
    "    \n",
    "    #for c in range(3):\n",
    "     #   im[:, :, c] = im[:, :, c] - mean_pixel[c]        \n",
    "\n",
    "    #im = im.transpose((2,0,1)) # convert the image to RGBA  # shame of im= (3,224,224)\n",
    "\n",
    "    \n",
    "    # this axis dimension is required becuase VGG was trained on a dimension\n",
    "    # of 1, 3, 224, 224 (first axis is for the batch size\n",
    "    # even though we are using only one image, we have to keep the dimensions consistent\n",
    "    #im = np.expand_dims(im, axis=0)  # shape of im = (1,3,224,224)\n",
    "    im = np.reshape(im,[1,256,256,3])\n",
    "    #image_features[0,:] = vgg16_model.predict(im)[0]\n",
    "    get_6rd_layer_output = K.function([vgg16_model.layers[0].input],\n",
    "                                  [vgg16_model.layers[-3].output])\n",
    "    image_features[0,:] =get_6rd_layer_output([im])[0]\n",
    "    return image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Black_Measles','Blackrot','Isariopsis',\"MDB_disease\",\"No_disease\",\"mildiou\",\"Spyder\"]\n",
    "#with open(metadata, 'w') as metadata_file:\n",
    "#    for row in range(210):\n",
    "#        c = y[row]\n",
    "#        metadata_file.write('{}\\n'.format(c))\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata_7_classes.tsv'), 'w')\n",
    "metadata_file.write('Class\\tName\\n')\n",
    "k=10 # num of samples in each class\n",
    "j=0\n",
    "#for i in range(210):\n",
    "#    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "for i in range(num_of_samples):\n",
    "    c = names[y[i]]\n",
    "    if i%k==0:\n",
    "        j=j+1\n",
    "    metadata_file.write('{}\\t{}\\n'.format(j,c))\n",
    "    #metadata_file.write('%06d\\t%s\\n' % (j, c))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.optimizers import SGD\n",
    "from keras import Sequential\n",
    "# image folder\n",
    "folder_path = '../Dataset/test/'\n",
    "# path to model\n",
    "model_path = 'resnet18.h5'\n",
    "mod = Sequential()\n",
    "\n",
    "# dimensions of images\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "mod = Sequential()\n",
    "\n",
    "mod.add(model)\n",
    "mod.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# load all images into a list\n",
    "images = []\n",
    "for img in os.listdir(folder_path):\n",
    "    img = os.path.join(folder_path, img)\n",
    "    img = image.load_img(img, target_size=(img_width, img_height))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    images.append(img)\n",
    "\n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "classes = mod.predict_classes(images, batch_size=10)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_path=\"../Dataset/test/MDB_disease/mdb1573.jpg\"\n",
    "img = image.load_img(image_path)\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict_classes(img)\n",
    "plt.title(get_label_name(result[0][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# dimensions of our images    -----   are these then grayscale (black and white)?\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "# load the model we saved\n",
    "model = load_model('resnetseq.h5')\n",
    "\n",
    "# Get test image ready\n",
    "#test_image = image.load_img('../Dataset/test/Isariopsis/Isariopsis 1306.JPG', target_size=(img_width, img_height))\n",
    "#test_image = image.img_to_array(test_image)\n",
    "#test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "#test_image = test_image.reshape(img_width, img_height)    # Ambiguity!\n",
    "# Should this instead be: test_image.reshape(img_width, img_height, 3) ??\n",
    "\n",
    "#result = model.predict(test_image, batch_size=1)\n",
    "#print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
