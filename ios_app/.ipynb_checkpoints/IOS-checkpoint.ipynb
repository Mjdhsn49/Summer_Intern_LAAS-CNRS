{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_model:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    " \n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    " \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    " \n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    " \n",
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images('dataset/')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    " \n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 3024.00MB\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "    data.nbytes / (1024 * 1000.0)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    " \n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = Custom_model.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "    depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 31/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0541 - acc: 0.9808 - val_loss: 0.3209 - val_acc: 0.9254\n",
      "Epoch 32/50\n",
      "350/350 [==============================] - 27s 76ms/step - loss: 0.0464 - acc: 0.9820 - val_loss: 0.1716 - val_acc: 0.9489\n",
      "Epoch 33/50\n",
      "350/350 [==============================] - 26s 76ms/step - loss: 0.0535 - acc: 0.9812 - val_loss: 0.0515 - val_acc: 0.9832\n",
      "Epoch 34/50\n",
      "350/350 [==============================] - 26s 75ms/step - loss: 0.0430 - acc: 0.9846 - val_loss: 0.0527 - val_acc: 0.9846\n",
      "Epoch 35/50\n",
      "350/350 [==============================] - 26s 75ms/step - loss: 0.0463 - acc: 0.9839 - val_loss: 0.1188 - val_acc: 0.9586\n",
      "Epoch 36/50\n",
      "350/350 [==============================] - 26s 75ms/step - loss: 0.0450 - acc: 0.9835 - val_loss: 0.6527 - val_acc: 0.8621\n",
      "Epoch 37/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0444 - acc: 0.9849 - val_loss: 1.2706 - val_acc: 0.8396\n",
      "Epoch 38/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0529 - acc: 0.9803 - val_loss: 0.0950 - val_acc: 0.9736\n",
      "Epoch 39/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0442 - acc: 0.9863 - val_loss: 0.0567 - val_acc: 0.9804\n",
      "Epoch 40/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0379 - acc: 0.9853 - val_loss: 0.0831 - val_acc: 0.9743\n",
      "Epoch 41/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0381 - acc: 0.9875 - val_loss: 0.3238 - val_acc: 0.9218\n",
      "Epoch 42/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0406 - acc: 0.9853 - val_loss: 0.0785 - val_acc: 0.9754\n",
      "Epoch 43/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0297 - acc: 0.9887 - val_loss: 0.4902 - val_acc: 0.8982\n",
      "Epoch 44/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0601 - acc: 0.9807 - val_loss: 0.0909 - val_acc: 0.9743\n",
      "Epoch 45/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0356 - acc: 0.9873 - val_loss: 0.0905 - val_acc: 0.9686\n",
      "Epoch 46/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0412 - acc: 0.9853 - val_loss: 0.0594 - val_acc: 0.9800\n",
      "Epoch 47/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0377 - acc: 0.9880 - val_loss: 0.0677 - val_acc: 0.9793\n",
      "Epoch 48/50\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.0331 - acc: 0.9885 - val_loss: 0.6235 - val_acc: 0.8611\n",
      "Epoch 49/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0350 - acc: 0.9877 - val_loss: 0.1278 - val_acc: 0.9621\n",
      "Epoch 50/50\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.0331 - acc: 0.9883 - val_loss: 0.0687 - val_acc: 0.9746\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,initial_epoch=30,epochs=50\n",
    "    , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network...\n",
      "[INFO] serializing label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('custom_model.h5')\n",
    " \n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open('lb.pickle', \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "# load the image\n",
    "image = cv2.imread('test.JPG')\n",
    "output = image.copy()\n",
    " \n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n"
     ]
    }
   ],
   "source": [
    "# load the trained convolutional neural network and the label\n",
    "# binarizer\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model('custom_model.h5')\n",
    "lb = pickle.loads(open('lb.pickle', \"rb\").read())\n",
    " \n",
    "# classify the input image\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = lb.classes_[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-2dae189be7a8>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-2dae189be7a8>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    filename = ['test.JPG''test.JPG'.rfind(os.path.sep) + 1:]\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# we'll mark our prediction as \"correct\" of the input image filename\n",
    "# contains the predicted label text (obviously this makes the\n",
    "# assumption that you have named your testing image files this way)\n",
    "filename = ['test.JPG''test.JPG'.rfind(os.path.sep) + 1:]\n",
    "correct = \"correct\" if filename.rfind(label) != -1 else \"incorrect\"\n",
    " \n",
    "# build the label and draw the label on the image\n",
    "label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, correct)\n",
    "output = imutils.resize(output, width=400)\n",
    "cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the output image\n",
    "print(\"[INFO] {}\".format(label))\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
